{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import hashlib\n",
    "import math\n",
    "from csv import reader\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "import re\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_str(to_hash): \n",
    "    stringToHash = to_hash.encode()\n",
    "    return hashlib.sha256(stringToHash).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lbl(line_list, filename): \n",
    "    data_list = []\n",
    "    i = 0\n",
    "    name_line = ''\n",
    "    while (i < len(line_list)): \n",
    "        if i+1 < len(line_list) and '---------,---------,---------,---------' in line_list[i+1]:\n",
    "            name_line = line_list[i].strip('\\n')     \n",
    "        elif \"---------,---------,---------,---------\" in line_list[i]: \n",
    "            pass\n",
    "        else: \n",
    "            for line in reader([filename+','+name_line+','+line_list[i].strip()]):\n",
    "                data_list.append(line)\n",
    "        i = i + 1\n",
    "    return data_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mem(line_list, filename): \n",
    "    data_list = []\n",
    "    i = 0\n",
    "    name_line = ''\n",
    "    setup = ''\n",
    "    app = ''\n",
    "    doc = ''\n",
    "    regex = ''\n",
    "    while (i < len(line_list)): \n",
    "        if 'Command being timed:' in line_list[i]:\n",
    "            # 'Command being timed: \"./target/release/reef --e2e --cmt-name cmt --proof-name proof --doc q1w2e3r4 --metrics ./tests/results/timings/bad_pass --re ^(?=.*[A-Z].*[A-Z])(?=.*[!%^@#$&*])(?=.*[0-9].*[0-9])(?=.*[a-z].*[a-z].*[a-z]).{12}$ -n -y ascii\"'\n",
    "            name_line = line_list[i]\n",
    "            if 'reef' in filename: \n",
    "                setup = 'reef'\n",
    "            elif 'safa' in filename: \n",
    "                setup = 'safa+nlookup'\n",
    "            elif 'nwr' in filename: \n",
    "                setup = 'nwr'\n",
    "            else: \n",
    "                setup = 'naive' \n",
    "            \n",
    "            regex = re.findall(\"--re (.*?) (-n )?(-p )?(-y )?(ascii|dna)\",name_line)[0][0]\n",
    "            app = re.findall(\"--metrics (.*?) --\",name_line)[0].split('/')[-1]\n",
    "\n",
    "            doc = re.findall(\"--doc (.*?) --\",name_line)[0]\n",
    "            doc_len = len(doc)\n",
    "\n",
    "            match app: \n",
    "                case 'bad_pass':\n",
    "                    doc = doc[:10]+\"_\"+str(doc_len)\n",
    "                case 'good_pass': \n",
    "                    doc = doc[:10]+\"_12\"\n",
    "                case 'email_dkim': \n",
    "                    if 'small' in filename: \n",
    "                        doc_len = 415 \n",
    "                    else: \n",
    "                        doc_len = 1000\n",
    "                    doc = \"Message-ID_\"+str(doc_len)\n",
    "                case 'pihole': \n",
    "                    doc = doc[:10]+\"_128\"\n",
    "                case 'brca1_var1_match': \n",
    "                    doc = doc[:10]+\"_43054295\"\n",
    "                case 'brca1_var1_nonmatch1': \n",
    "                    doc = doc[:10]+\"_43054295\"\n",
    "                case 'brca1_var1_nonmatch2': \n",
    "                    doc = doc[:10]+\"_43054295\"\n",
    "                case 'brca1_var2_match': \n",
    "                    doc = doc[:10]+\"_43054295\"\n",
    "                case 'brca1_var2_nonmatch1': \n",
    "                    doc = doc[:10]+\"_43054295\"\n",
    "                case 'brca1_var2_nonmatch2': \n",
    "                    doc = doc[:10]+\"_43054295\"\n",
    "                case 'brca2_var1_match': \n",
    "                    doc = doc[:10]+\"_32325508\"\n",
    "                case 'brca2_var1_nonmatch': \n",
    "                    doc = doc[:10]+\"_32325508\"                \n",
    "        elif \"Maximum resident set size\" in line_list[i]: \n",
    "            mem_usage = int(line_list[i].split(':')[1].strip())*1e3\n",
    "            data_list.append([app, setup, regex, doc, mem_usage])\n",
    "        else: \n",
    "           pass\n",
    "        i = i + 1\n",
    "    return data_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests/results/memory/pw_bad_reef\n",
      "tests/results/memory/email_med_reef\n",
      "tests/results/memory/pw_bad_safa_nlookup\n",
      "tests/results/memory/email_small_safa_nlookup\n",
      "tests/results/memory/email_med_nwr\n",
      "tests/results/memory/pihole_nwr\n",
      "tests/results/memory/dna_reef\n",
      "tests/results/memory/email_small_naive\n",
      "tests/results/memory/pihole_reef\n",
      "tests/results/memory/email_small_nwr\n",
      "tests/results/memory/pihole_naive\n",
      "tests/results/memory/email_med_naive\n",
      "tests/results/memory/email_med_safa_nlookup\n",
      "tests/results/memory/pihole_safa_nlookup\n",
      "tests/results/memory/email_small_reef\n",
      "tests/results/memory/pw_good_reef\n",
      "tests/results/memory/dna_safa_nlookup\n",
      "tests/results/memory/pw_good_safa_nlookup\n"
     ]
    }
   ],
   "source": [
    "mem_data = []\n",
    "mem_directory = 'tests/results/memory'\n",
    " \n",
    "for filename in os.listdir(mem_directory):\n",
    "    filepath = os.path.join(mem_directory, filename)\n",
    "    if 'Data' not in filename and 'DS_Store' not in filename and os.path.isfile(filepath):\n",
    "        print(filepath)\n",
    "        f = open(filepath, \"r\")\n",
    "        lbl = [x for x in f]\n",
    "        f.close()\n",
    "        mem_data.extend(process_mem(lbl,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests/results/timings/brca1_var2_nonmatch1\n",
      "tests/results/timings/brca1_var1_nonmatch2\n",
      "tests/results/timings/brca2_var1_match\n",
      "tests/results/timings/brca1_var1_match\n",
      "tests/results/timings/brca1_var2_nonmatch2\n",
      "tests/results/timings/good_pass\n",
      "tests/results/timings/bad_pass\n",
      "tests/results/timings/brca1_var2_match\n",
      "tests/results/timings/brca1_var1_nonmatch1\n",
      "tests/results/timings/email_dkim\n",
      "tests/results/timings/pihole\n",
      "tests/results/timings/brca2_var1_nonmatch\n"
     ]
    }
   ],
   "source": [
    "time_data = []\n",
    "time_directory = 'tests/results/timings'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.listdir(time_directory):\n",
    "    filepath = os.path.join(time_directory, filename)\n",
    "    if 'Data' not in filename and 'DS_Store' not in filename and os.path.isfile(filepath):\n",
    "        print(filepath)\n",
    "        f = open(filepath, \"r\")\n",
    "        lbl = [x for x in f]\n",
    "        f.close()\n",
    "        time_data.extend(process_lbl(lbl,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_df = pd.DataFrame(mem_data, columns = ['app','setup','regex','doc','val'])\n",
    "num_cols = ['val']\n",
    "mem_df[num_cols] = mem_df[num_cols].apply(pd.to_numeric,errors='coerce', axis=1)\n",
    "mem_df['hash_id'] = mem_df.apply(lambda x: hash_str(x.doc+x.regex+x.app)[:5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(time_data, columns = ['app','doc','setup','time','regex','n_transitions','n_states',\n",
    "                                    'test_type','component','test','val','metric'])\n",
    "num_cols = ['time','n_transitions','n_states','val']\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric,errors='coerce', axis=1)\n",
    "\n",
    "naive_sub = df.loc[(df.setup=='naive') \n",
    "       & (df.test.isin(['witness_generation','prove_0']))\n",
    "      ].groupby(['time', 'regex','app','doc','setup','n_transitions','n_states','test_type']).sum().reset_index()\n",
    "naive_sub['metric']='Î¼s'\n",
    "naive_sub['component'] = 'T'\n",
    "naive_sub['test'] = 'prove+wit'\n",
    "df = pd.concat([df,naive_sub])\n",
    "df['hash_id'] = df.apply(lambda x: hash_str(x.doc+x.regex+x.app)[:5], axis=1)\n",
    "df.loc[df.test=='prove+wit','component'] = 'T'\n",
    "df.reset_index(inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
